# -*- coding: utf-8 -*-
"""Proyek_Predictive_Analytics_Machine_Maintainance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/139XxMo8OsAU4oKbbJDEXS-hjTjzIg0YG

# Proyek Predictive Analytics: Machine Predictive Maintenance
- **Nama:** Abid Juliant Indraswara
- **Email:** abidjuliant@gmail.com
- **ID Dicoding:** abidindraswara

Fokus pada pengembangan dalam upaya menentukan prediksi tingkat kegagalan dan kelayakan mesin beroperasi. Nantinya dapat digunakan acuan dalam penentuan maintenance mesin.

## Project Scope

Latar Belakang

Mesin dalam artian umum dikaitkan dengan suatu objek yang dapat merubah suatu sumber energi menjadi energi dalam upaya mempermudah pekerjaan atau menghasilkan sesuatu. Mesin hampir selalu berkaitan dengan yang namanya komponen motor (kebalikan dari generator atau versi kecil dinamo) yang memiliki sifat sementara. Mesin motor ini pada pabrik usaha kecil, menengah maupun besar memberikan akses kemudahan manusia dalam mengelola dan mempermudah pekerjaan misalnya traktor untuk membajak sawah, conveyor untuk memindahkan barang, mesin press, lift, eskalator dan sejenisnya.

Penggunaannya secara waktu juga beraneka ragam namun di pabrik mesin motor sebisa mungkin 24 jam harus berjalan atau setidaknya tetap dalam kondisi on karena starting motor di pabrik membutuhkan warm up lama dan membutuhkan biaya yang besar kecuali pada saat maintenance yang umunya dilakukan setahun sekali tepatnya di hari raya besar [\[1\]](https://doi.org/10.1109/CSNT51715.2021.9509696). Kebutuhan akan mesin bisa dikatakan sudah melekat di jaman modern sekarang, namun ada beberapa hal yang menjadi perhatian salah satunya mengenai kualitas mesin. Kualitas mesin ditentukan oleh banyak faktor namun penggunaan yang berlebihan dapat menyebabkan kualitas mesin menurun berakibat pada gagalnya mesin bekerja [\[2\]](https://doi.org/10.1109/AI4I49448.2020.00023).

Dalam upaya pencegahan kualitas menurun perlu adanya perawatan (maintenace). Perawatan sendiri berguna untuk menjaga kualitas mesin dan deteksi dini agar tidak terjadi kegagalan mesin bekerja. Perawatan dilakukan dalam kurun waktu tertentu atau melihat dari beberapa faktor yang barangkali bisa menjadi deteksi dini kegagalan mesin sehingga bisa dilakukan perawatan lebih awal [\[3\]](http://dx.doi.org/10.3390/app10010213). Oleh karenanya perlu suatu sistem yang dapat melakukan prediksi kualitas mesin untuk dapat melakukan deteksi dini kualitas atau gangguan mesin dalam upaya maintenance awal.

## Business Understanding

Prediksi kualitas mesin untuk dapat menentukan perawatan mesin yang tepat diperlukan beberapa kriteria yang mecakup pada mesin motor. Mesin memiliki banyak jenis namun pada projek ini dimaksudkan pada mesin motor secara umum. Mesin dapat mengalami kerusakan yang timbul diantaranya akibat penggunaan yang berlebihan baik segi waktu, bobot maksimal yang dilewati, mesin terlalu panas, gangguan eksternal dan lain lain. Kerusakan tersebut dapat diminimalisir dengan perawatan yang baik dan tepat. Melakukan prediksi untuk mesin mana yang memiliki ciri-ciri serta menklasifikasikannya ke kategori tertentu dapat memberikan jawaban untuk bisa meminimalisir kerusakan dan deteksi dini kegagalan mesin. Mesin dapat bekerja dengan baik dan maksimal dengan perawatan yang baik dan konsisten.

### Problem Statment
- Sistem seperti apa yang dibuat dalam upaya menentukan prediksi perawatan mesin yang baik?
- Faktor apa yag paling berpengaruh dalam menentukan prediksi perawatan mesin?
- Mesin seperti apa yang mempunyai kualitas baik dan kualitas buruk sehingga perlu dilakukan perawatan?


### Goals
- Sistem prediksi perawatan mesin dibuat melalui sistem klasifikasi dengan integrasi kecerdasan buatan berbasis machine learning sistem.
- Faktor yang paling berpengaruh terhadap prediksi perawatan mesin dapat ditentukan melalui korelasi antar faktor terhadap kelas kategori kualitas mesin.
- Mesin dengan kualitas baik dan buruk bisa dilihat dari faktor-faktor yang sudah tersedia.

### Metodologi

Prediksi perawatan mesin terdapat beberapa kategori dengan nilai tertentu. Kategori mesin termasuk ke dalam permasalahan klasifikasi. Sehingga metodologi yang cocok untuk pada projek ini adalah membangun model klasifikasi dengan kategori target dan tipe kegagalan sebagai kelas.

### Metrik Evaluasi

Metrik evaluasi pada model klasifikasi umumnya digunakan accuracy, precision, recall, F-1 score dan confusion matrix. Metrik evaluasi yang disebutkan mengukur ketepatan dalam mengklasifikasikan suatu ketagori bergantung pada jenis data, imbangan kelas dan tujuan spesifik model.

Pengembangan model menggunakan beberapa algoritma machine learning seperti K-Nearest Neighbor, SVM, Decision Tree, Random Forest, dan Boosting Algorithm. Kelima model diatas akan dipilih satu model prediksi yang paling akurat dengan akurasi prediksi tertinggi.

Membuat model prediktif pada machine learning sangat membutuhkan data. Pda mesin maintenance terdapat data yang dapat diakses secara open-source di kaggle. Dataset machine predictive maintenance classification pada link berikut [dataset](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification/data) . Merupakan dataset sintetis yang merefleksikan prediksi perawatan mesin secara real-world yang ditemui di industri.

## Data Understanding

Dataset yang digunakan adalah Machine Predictive Maintenance Classification dari Kaggle pada [link](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification/data) berikut. Paper dipublikasikan oleh Stephan Matzka pada 2020 di platform IEEE yang berjudul "[Explainable Artificial Intelligence for Predictive Maintenance Applications](https://doi.org/10.1109/AI4I49448.2020.00023)". Dataset ini cukup besar sehingga cukup satu ini digunakan dalam membuat model klasifikasi.

Dataset prediksi perawatan mesin secara umum sulit untuk didapatkan dan dipublikasikan khususnya penggunaan di industri pabrik hal ini terkait masalah privasi yang ada. Sehingga dataset yang akan digunakan projek nantinya merupakan kumpulan data sintetis yang mencerminkan data nyata pemeliharaan prediktif yang sering ditemui di industri. Dataset terdiri dari 10000 data poin berdasarkan UID (Unique ID) dengan 10 fitur kolom. Beberapa 10 fitur atau parameter tersebut diantaranya
- UID merupakan identifikasi unik dari setiap data dari 1 hingga 10000 jumlahnya sesuai yang ada di dataset.
- ProductID yaitu variasi spesifik serial number yang direpresentasikan sebagai type dengan 3 jenis tipe L, M dan H.
- Type berisi data dengan keterangan L untuk low (50% dari keseluruhan produk), M untuk medium (30% dari keseluruhan produk) dan H untuk high (20% dari keseluruhan produk) yang merupakan jenis kualitas produk.
- Air Temperatue [K] merupakan data temperatur udara yang dihasilkan dari proses random kemudian dinormalisasi ke standar deviasi dengan rentangnilai 2 K hingga 300 K.
- Process Temperature [K] merupakan data temperatur proses yang dihasilkan dari proses random kemudian dinormalisasi ke standar deviasi dengan nilai 1 K ditambahkan dengan temperatur udara ditambah 10 K.
- Rotational Speed [rpm] yaitu kecepatan rotasi dihitung dari daya 2860 W, dilapisi dengan kebisingan yang didistribusikan secara normal.
- Torque [Nm] yaitu nilai torsi umumnya terdistribusi sekitar 40 Nm dengan Ïƒ = 10 Nm dan tidak ada memiliki nilai negatif.
- Tool Wear [min] merupakan varian kualitas H/M/L dengan menambahkan keausan alat selama 5/3/2 menit pada alat yang digunakan dalam proses tersebut serta label 'machine failure' yang menunjukkan apakah mesin telah gagal pada titik data khusus dengan salah satu mode kegagalan adalah True.
- Target merupakan nilai kategori target dengan nilai Failure atau Not.
- Failure Type merupakan nilai kategori target terdiri 5 mode kegagalan yaitu no failure, heat dissipation failure, power failure, overstrain failure dan tool wear failure.

Pada parameter target dan failure type merupakan kolom target dari model klasifikasi yang akan dibuat. Target memiliki dua nilai sehingga bisa dikatakan binary classification. Sedangkan Failure type memiliki 5 nilai sehingga bisa dikatakan multi classification. Sisa kolom mendefinisikan ID, ProductID, Type serta lainnya ciri-ciri dari kegagalan mesin dengan nilai tertentu.

### Import Libraries

Beberapa library yang dibutuhkan dari mulai import data, pengolahan data, pembuatan model, evalusasi model hingga deployment.
"""

# Import Library Umum
import os, shutil
from shutil import copyfile
import zipfile
import pathlib
from pathlib import Path
import numpy as np
import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
# Import Library Visualisasi
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from matplotlib.image import imread
import seaborn as sns

# Import Library Preprocessing dan Machine Learning
import tensorflow as tf
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler
from sklearn.metrics import confusion_matrix,classification_report, accuracy_score, roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier # KNN
from sklearn.svm import SVC # SVM
from sklearn.tree import DecisionTreeClassifier # Decision Tree
from sklearn.ensemble import RandomForestClassifier # Random Forest
from xgboost import XGBClassifier # XGBoost

"""### Import Dataset

Import dataset melalui platform kaggle secara langsung dengan menghubungkan nya melalui token API.
"""

# Mengambil data melalui google drive dengan melakukan autentikasi akun

from google.colab import drive
drive.mount('/content/drive')

# Install Libraru Kaggle
!pip install kaggle

# Upload file kaggle.json menggunakan token API akses melalui akun
from google.colab import files
files.upload()

# Hubungkan ke Kaggle melalui token API
!chmod 600 /content/kaggle.json

# Download dataset .zip ke dalam Google Drive
!kaggle datasets download -d shivamb/machine-predictive-maintenance-classification -p '/content/drive/My Drive/Dataset_MachineLearning/Dataset_Machine_Maintenance'

# Cek Folder Google Drive
!ls '/content/drive/My Drive/Dataset_MachineLearning/Dataset_Machine_Maintenance'

"""### Data Loading

Load dataset kemudian simpan ke dalam folder colab dan variabel agar mudah dipanggil.
"""

# Membuat direktori baru untuk menampung data gambar
!mkdir /content/machine_maintain

# Ekstrak Dataset
zip_ref = zipfile.ZipFile("/content/drive/My Drive/Dataset_MachineLearning/Dataset_Machine_Maintenance/machine-predictive-maintenance-classification.zip", 'r')
zip_ref.extractall("/content/machine_maintain")
zip_ref.close()

# Dataset Machine Maintenance
machine_df = pd.read_csv("/content/machine_maintain/predictive_maintenance.csv")
machine_df

"""### Exploratory Data Analysis - Deskripsi Variabel

Eksplorasi data untuk mengetahui info mengenai dataset beserta variabelnya.

#### Dataset Info
"""

# Cek Info Kolom Dataset
print('Informasi Dataset Machine Maintenance')
print(machine_df.info())

"""Jika dilihat melalui informasi diatas diketahui bahwa semua kolom tidak memiliki nilai null. Namun masih perlu dicek apakah nilainya kosong atau NaN karena akan berdampak pada model. Diketahui juga jika kolom Product ID, Type dan Failure Type memiliki tipe data object. Sedangkan UID, Air temperature, Process temperature, Rotational speed, Torque dan Tool wear memiliki tipe data number.

#### Dataset Describe
"""

# Cek Deskripsi Dataset
print('Deskripsi Dataset Machine Maintenance')
print(machine_df.describe())

"""Fokus pada describe untuk mengetahui jumlah data, nilai rata-rata, standar deviasi, minimum, maksimum dan nilai kuartal. Kolom UID diabaikan karena termasuk nilai dengan tipe data ID yang tentunya unik.

#### Dataset Check Null
"""

# Cek Null Dataset
print('Cek Null Dataset Machine Maintenance')
print(machine_df.isnull().sum())

"""Tidak terdapat nilai null pada dataset, sehingga cleansing data null tidak diperlukan.

#### Dataset Check NaN
"""

# Cek NaN Dataset
print('Cek NaN Dataset Machine Maintenance')
print(machine_df.isna().sum())

"""Begitu juga dengan nilai NaN tidak terdapat nilai NaN pada data sehingga tidak perlu dilakukan cleansing untuk data NaN.

#### Dataset Check Duplicate
"""

# Cek Duplikat Data pada Dataset Machine Maintenance
print('Cek Duplikat Data pada Dataset Machine Maintenancey : ', machine_df.duplicated().sum())

"""Duplikat data tidak muncul karena semuanya bersifat unik dan data pada kolom UID total 10000 bisa dikatakan aman.

#### Dataset Check Outlier

Karena memiliki 10000 data maka perlu sebuah visual untuk mengukur seberapa banyak outlier yang muncul. Ada beberapa cara yang dapat digunakan seperti boxplot dengan melihat nilai interquartil maupun secara persebaran data dengan data histogram. Data yang akan dicek tentunya adalah data angka di 5 kolom yaitu Air temperature, Process temperature, Rotational speed, Torque dan Tool wear.

##### Boxplot Check Outlier

###### Air Temperature
"""

# Boxplot Check Outlier Kolom Air Temperature
print('Boxplot Check Outlier Kolom Air Temperature\n')
sns.boxplot(x=machine_df['Air temperature [K]'])

"""###### Process Tempoerature"""

# Boxplot Check Outlier Kolom Process Temperature
print('Boxplot Check Outlier Kolom Process Temperature\n')
sns.boxplot(x=machine_df['Process temperature [K]'])

"""###### Rotational Speed"""

# Boxplot Check Outlier Kolom Rotational Speed
print('Boxplot Check Outlier Kolom Rotational Speed\n')
sns.boxplot(x=machine_df['Rotational speed [rpm]'])

"""###### Torque"""

# Boxplot Check Outlier Kolom Torque
print('Boxplot Check Outlier Kolom Torque\n')
sns.boxplot(x=machine_df['Torque [Nm]'])

"""###### Tool Wear"""

# Boxplot Check Outlier Kolom Tool Wear
print('Boxplot Check Outlier Kolom Tool Wear\n')
sns.boxplot(x=machine_df['Tool wear [min]'])

"""Bisa dilihat pada hasil boxplot diatas dari kelima kolom terdapat 2 kolom yang memiliki outlier yaitu kolom rotational speed dan kolom torque.

##### Histogram Check Data Distribution

###### Air Temperature
"""

# Boxplot Check Outlier Kolom Air Temperature
print('Histogram Check Distribution Data Kolom Air Temperature\n')
machine_df['Air temperature [K]'].hist()

"""###### Process Temperature"""

# Boxplot Check Outlier Kolom Process Temperature
print('Histogram Check Distribution Data Kolom Process Temperature\n')
machine_df['Process temperature [K]'].hist()

"""###### Rotational Speed"""

# Boxplot Check Outlier Kolom Rotational Speed
print('Histogram Check Distribution Data Kolom Rotational Speed\n')
machine_df['Rotational speed [rpm]'].hist()

"""###### Torque"""

# Boxplot Check Outlier Kolom Torque
print('Histogram Check Distribution Data Kolom Torque\n')
machine_df['Torque [Nm]'].hist()

"""###### Tool Wear"""

# Boxplot Check Outlier Kolom Tool Wear
print('Histogram Check Distribution Data Kolom Tool Wear\n')
machine_df['Tool wear [min]'].hist()

"""#### Dataset Update Nama Kolom UDI menjadi UID"""

# Mengubah nama kolom 'UDI' menjadi 'UID'
machine_uid_df = machine_df.rename(columns={'UDI': 'UID'}, inplace=True)

machine_uid_df = machine_df

machine_uid_df.head()

"""### Exploratory Data Analysis - Univariate Analysis

Eksplorasi data dengan metode Univariate Analysis yaitu analisis yang melibatkan satu variabel tunggal. Tujuan utamanya adalah untuk memahami distribusi, karakteristik, dan pola data dari satu variabel tersebut. Pada eksplorasi multivariate bisa menggunakan pairplot dan heatmap.
"""

numerical_features = ['UID', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Target']
categorical_features = ['Product ID', 'Type', 'Failure Type']

"""#### Categorical Features

##### Type
Type mendefinsikan isi yang ada di dalam kolom Product ID sehingga hanya perlu Type saja untuk melihat analisisnya.
"""

feature = categorical_features[1]
count = machine_uid_df[feature].value_counts()
percent = 100*machine_uid_df[feature].value_counts(normalize=True)
category_uni_df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(category_uni_df)
count.plot(kind='bar', title=feature);

"""##### Failure Type"""

feature = categorical_features[2]
count = machine_uid_df[feature].value_counts()
percent = 100*machine_uid_df[feature].value_counts(normalize=True)
category_uni_df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(category_uni_df)
count.plot(kind='bar', title=feature);

"""#### Numerical Features
Pada bagian ini adalah untuk melihat seberapa banyak data di masing-masing kelas kategori
"""

machine_uid_df.hist(bins=50, figsize=(20,15))
plt.show()

"""##### Target"""

# Menghitung jumlah label pada fitur Target
sns.countplot(data=machine_uid_df, x='Target')

# Menambahkan label dan judul
plt.title('Distribution of Target')
plt.xlabel('Target')
plt.ylabel('Count')

"""### Exploratory Data Analysis - Multivariate Analysis

Eksplorasi data dengan metode Multivariate Analysis yaitu analisis yang melibatkan lebih dari satu variabel sekaligus. Tujuan dari analisis ini adalah untuk memahami hubungan dan interaksi antara dua atau lebih variabel dalam dataset. Pada eksplorasi multivariate bisa menggunakan pairplot dan heatmap.

##### Categorical Features
"""

# category_multi_features = fix_outlier_df.select_dtypes(include='object').columns.to_list()
category_multi_features = ['Type', 'Failure Type']

for col in category_multi_features:
  sns.catplot(x=col, y="Torque [Nm]", kind="bar", dodge=False, height = 4, aspect = 3,  data=machine_uid_df, palette="Set3")
  plt.title("Rata-rata 'Torque' Relatif terhadap - {}".format(col))

"""##### Numerical Feaures"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(machine_uid_df, diag_kind = 'kde')

numerical_features = ['UID', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Target']
categorical_features = ['Type', 'Failure Type']

plt.figure(figsize=(10, 8))
correlation_matrix = machine_uid_df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='RdYlBu', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""## Data Preparation

Data preparation yaitu tahapan untuk melakukan transformasi data agar sesuai atau dapat dengan mudah digunakan ketika modeling machine learning. Bagian data preparation yang umum dilakukan ada beberapa tahapan diantaranya:
- Encoding Fitur Kategori
- Seleksi Fitur
- Pembagian dataset dengan fungsi train_test_split dari library sklearn
- Normaliasi Data

Tahapan diatas secara berurutan dijalankan melalui proses encoding untuk mengubah bentuk kolom kategori. Encoding dilakukan pada tahapan awal agar nantinya mudah dalam melakukan seleksi fitur karena kolom yang tersedia akan jadi bertambang melalui proses encoding. Selanjutnya seleksi fitur dilakukan dengan membagi ke dalam kolom mana saja yang merupakan data dan label. Seleksi fitur akan mengacu pada kolom setelah encoding. Setelah itu baru bisa membagi data ke dalam data train dan data test untuk nantinya digunakan dalam modeling dan testing. Terakhir data pre tahapannya adalah melakukan normalisasi data setelah pembagian data train dan test.

Berikut penjelasan tahapan diatas:
1. Dataset Menghilangkan Outlier :
Pada bagian EDA - Deskripsi Variabel terlihat bahwa dataset yang dimiliki mempunyai outlier yang cukup banyak. Sehingga perlu dilakukan penyesuaian agar data yang dimiliki mampu mempunyai model yang baik dalam melakukan prediksi. Outlier sangat mengganggu pelatihan model menjadikan prediksi bisa saja underfitting karena tidak mampu mendeteksi klasifikasi yang sesuai. Untuk menghindari outlier ada cara yang digunakan yaitu mengetahui batas bawah dan batas atas kemudian bisa melakukan remove pada data yang tidak sesuai dengan rumus tersebut.
2. Encoding Fitur Kategori :
Hal ini terkait dengan beberapa fitur kategori yang ada pada kolom Type dan Failure Type, perlu dilakukan penyesuaian agar model yang nantinya dibuat bisa membaca dengan baik. Jadi kedua kolom tersebut perlu diubah bentuknya menjadi beberapa kolom lagi yang mendefinisikan nilai numerik dari kategori yang dimaksud. Teknik yang yang digunakan adalah one-hot encoding yang sudah tersedia di library scikit-learn.
3. Seleksi Fitur :
Seleksi fitur digunakan untuk mengelompokkan data yang termasuk ke dalam variabel data dan variabel label. Karena berbentuk klasifikasi maka variabel label yang terdiri dari beberapa kelas kualitas mesin akan digunakan dalam acuan prediksi data perawatan mesin.
4. Pembagian dataset dengan fungsi train_test_split dari library sklearn :
Variabel data dan variabel label perlu dibagi menjadi 2 secara terpisah yaitu yang termasuk ke dalam data train dan data test. Data train digunakan untuk membentuk model sedangkan data test digunakan untuk menguji seberapa baik model yang dibuat terhadap data test.
5. Standardisasi Data
Standardisasi data merupakan tahapan dimana data akan dilakukan proses scaling dan standardisasi sehingga data yang sebelumnya memiliki nilai rentang bilangan bulat ataupun desimal menjadi bernilai rentang antara -1 s.d 1 dengan menggunakan metode Z-score scaling. Hal ini perlu dilakukan karena sistem komputer cenderung dapat mengenali suatu nilai -1 hingga 1.

#### Dataset Menghilangkan Outlier

Outlier muncul pada kolom Rotational Speed dan kolom Torque sehingga perlu disesuaikan.
"""

# Fungsi untuk menghapus outlier menggunakan IQR
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    # Menentukan batas bawah dan batas atas
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Menghapus baris yang berada di luar batas bawah dan batas atas
    # return df[~((df[column]<(lower_bound))|(df[column]>(upper_bound)))]
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Menghilangkan outlier pada kolom 'Rotational speed [rpm]'
rotation_df = remove_outliers(machine_uid_df, 'Rotational speed [rpm]')

# Menghilangkan outlier pada kolom 'Torque [Nm]'
fix_outlier_df = remove_outliers(rotation_df, 'Torque [Nm]')

# Boxplot Check Outlier Kolom Rotational Speed
print('Boxplot Check Outlier Kolom Rotational Speed\n')
sns.boxplot(x=fix_outlier_df['Rotational speed [rpm]'])

# Boxplot Check Outlier Kolom Torque
print('Boxplot Check Outlier Kolom Torque\n')
sns.boxplot(x=fix_outlier_df['Torque [Nm]'])

fix_outlier_df.shape

fix_outlier_df.info()

"""### Encoding Fitur Kategori

Terdapat 2 kolom fitur kategori yang peru disesuaikan yaitu kolom Type dan kolom Failure Type.
"""

# Enccoding Fitur Kategori
encode_df = pd.concat([fix_outlier_df, pd.get_dummies(fix_outlier_df['Type'], prefix='Type')],axis=1)
encode_df = pd.concat([encode_df , pd.get_dummies(encode_df ['Failure Type'], prefix='Failure Type')],axis=1)
encode_df.drop(['Type', 'Failure Type'], axis=1, inplace=True)
encode_df.head()

encode_df.info()

"""### Seleksi Fitur

Pada bagian seleksi fitur akan berfokus pada pembagian kolom ke dalam variabel data dan variabel label. Kolom UID dan Product ID akan di takeout karena termasuk nilai identifikasi unik hal ini dimaksudkan agar model yang dibuat tidak terpengaruh UID dan Product ID. Karena yang diketahui bahwa kolom unik tidak memberikan efek apapun pada pelatihan karena terkait produk mesin atau barangkali ID record tertentu. Variabel data terdiri dari beberapa kolom numerik dan kolom kategori yaitu air temperature, process temperature, rotational speed, torque, tool wear, type_h, type_l, type_m, Failure Type_Heat Dissipation Failure, Failure Type_No Failure, Failure Type_Overstrain Failure, Failure Type_Power Failure, Failure Type_Random Failures dan Failure Type_Tool Wear Failure. Sedangkan untuk variabel label merupakan kolom kategori target yang berisi nilai 0 dan 1.

Untuk label sebenarnya masih bisa dikembangkan ke dalam bentuk multicalssification karena berdasarkan kolom failure type. Namun pada kesempatan ini akan berfokus pada dua klasifikasi target 1 dan 0 atau bisa dikatakan 1 sebagai mesin yang perlu pemeliharaan sedangkan 0 sebagai mesin yang masih aman.
"""

# Drop Kolom UID dan Poduct ID
drop_id_df = encode_df.drop(['UID', 'Product ID'], axis=1, inplace=False)
drop_id_df.head()

drop_id_df.info()

# Variabel Data [X]
# Memilih kolom-kolom data
X = drop_id_df[['Air temperature [K]',
                'Process temperature [K]',
                'Rotational speed [rpm]',
                'Torque [Nm]',
                'Tool wear [min]',
                'Type_H',
                'Type_L',
                'Type_M',
                'Failure Type_Heat Dissipation Failure',
                'Failure Type_No Failure',
                'Failure Type_Overstrain Failure',
                'Failure Type_Power Failure',
                'Failure Type_Random Failures',
                'Failure Type_Tool Wear Failure'
    ]]

X.head()

# Variabel Data [y]
# Memilih kolom label Target
y = drop_id_df["Target"]
y.head()

"""### Train_Test_Split Dataset
Tahapan ini dilakukan untuk membagi data yang akan dibutuhkan untuk modeling dan data yang dibutuhkan untuk testing.
"""

# Train Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

# Cek Hasil Split Data
print(f'Total Jumlah Data          : {len(X)}')
print(f'Total Jumlah Data Training : {len(X_train)}')
print(f'Total Jumlah Data Testing  : {len(X_test)}')

"""### Standardisasi

Dilakukan untuk menyeterakan nilai yang sama pada setiap kolom numerik dengan rentang 0 hingga 1. Sehingga sistem komputer akan mudah melakukan pembacaan dan training model.
"""

# Standardisasi Nilai Numerik
numerical_features = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

# Cek dan Pastikan sudah Standardisasi
X_train[numerical_features].describe().round(4)

"""## Model Development

Bagian model development akan berfokus pada pembuatan model dengan beberapa algoritma machine learning sebagai solusi untuk problem statemen yang muncul di awal. Ada beberapa algoritma yang bisa digunakan pada projek ini untuk dicoba dan dipilih mana model yang terbaik. Algoritma yang akan digunakan diantaranya :   
1. K-Nearest Neighbor
2. SVM
3. Decision Tree
4. Random Forest
5. Boosting Algorithm

Masing-masing algoritma diatas memiliki kelebihan dan kekurangan masing-masing yang akan dijabarkan pada tiap bagiannya.

### Algoritma K-Nearest Neighbor

Algoritma KNN atau singkatan dari K-Nearest Neighbor merupakan algoritma machine learning tipe supervised learning yang umumnya digunakan pada permasalahan klasifikasi atau regresi. Bekerja dengan cara mencari K tertangga terdekat (disebut neighbors) dari data yang ingin diprediksi. Algoritma ini mengambil mayoritas kelas dari tetangga terdekat untuk klasifikasi atau rata-rata nilai untuk regresi.

Kelebihan :

- Salah satu algoritma yang paling mudah dipahami dan diimplementasikan.
- Algoritma ini adalah instance-based learning, yang berarti tidak perlu fase pelatihan eksplisit, cukup menyimpan dataset untuk digunakan saat prediksi.
- KNN bekerja dengan baik pada dataset kecil hingga menengah.

Kekurangan :

- KNN memerlukan waktu komputasi yang besar saat melakukan prediksi karena perlu menghitung jarak ke semua data latih, sehingga tidak efisien untuk dataset besar.
- Karena berbasis pada jarak, KNN sangat sensitif terhadap skala fitur dan noise dalam data.
- KNN menyimpan seluruh dataset, yang bisa memakan banyak memori, terutama untuk dataset besar.

#### Prepare Dataframe untuk Kelima Analisis Model
"""

# Siapkan Dataframe untuk Analisis Model
models = pd.DataFrame(index=['train_acc', 'test_acc'],
                      columns=['KNN', 'SVM', 'Decision Tree', 'Random Forest', 'XGBoost'])

"""#### Create Model"""

# Model KNN
knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train, y_train)

"""#### Predict"""

# Prediksi dengan Model KNN
y_pred_knn = knn.predict(X_test)

"""#### Metric Evaluasi"""

# Menghitung Confusion Matrix dan Accuracy
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)
accuracy_knn_train = accuracy_score(y_train, knn.predict(X_train))
accuracy_knn_test = accuracy_score(y_test, y_pred_knn)

print("KNN Confusion Matrix  : ")
print(conf_matrix_knn)
print("KNN Accuracy Training : ", accuracy_knn_train)
print("KNN Accuracy Testing  : ", accuracy_knn_test)

"""#### Heatmap Confusion Matrix"""

# Membuat heatmap dari confusion matrix
knn_heatmap = sns.heatmap(conf_matrix_knn, annot=True, cmap='Greens')

# Mengatur judul dan label
knn_heatmap.set_title('Confusion Matrix Model KNN\n\n')
knn_heatmap.set_xlabel('\nPredicted Values')
knn_heatmap.set_ylabel('Actual Values ')

# Mengatur label x dan y
knn_heatmap.xaxis.set_ticklabels(['False', 'True'])
knn_heatmap.yaxis.set_ticklabels(['False', 'True'])

"""#### Save Metric Evaluasi"""

# Simpan Model untuk Analisis
models.loc['train_acc','KNN'] = accuracy_knn_train
models.loc['test_acc','KNN'] = accuracy_knn_test

"""### Algoritma SVM (Support Vector Machine)

Algoritma SVM atau singkatan dari Support Vector Machine merupakan algoritma machine learning tipe supervised learning yang umumnya digunakan pada permasalahan klasifikasi atau regresi. SVM bekerja dengan mencari hyperplane terbaik yang memisahkan data menjadi dua kelas. Pada kasus non-linear, kernel digunakan untuk mengubah data ke dimensi yang lebih tinggi agar pemisahan lebih mudah dilakukan

Kelebihan :

- SVM sangat baik untuk bekerja dengan data yang memiliki banyak fitur (berdimensi tinggi).
- Algoritma SVM bekerja dengan baik ketika kelas terpisah dengan jelas dalam data.
- Karena margin yang jelas, SVM cenderung menghindari overfitting.

Kekurangan :

-  SVM memerlukan waktu komputasi yang besar, terutama pada dataset besar, karena mencari hyperplane optimal memerlukan perhitungan yang intensif.
- Pilihan kernel yang buruk atau parameter yang tidak optimal dapat membuat SVM kurang efektif.
- SVM dapat bekerja buruk jika dataset memiliki banyak noise atau overlap antara kelas.

#### Create Model
"""

# Model SVM
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)

"""#### Predict"""

# Prediksi dengan Model SVM
y_pred_svm = svm.predict(X_test)

"""#### Metric Evaluasi"""

# Menghitung Confusion Matrix dan Accuracy
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
accuracy_svm_train = accuracy_score(y_train, svm.predict(X_train))
accuracy_svm_test = accuracy_score(y_test, y_pred_svm)

print("SVM Confusion Matrix  : ")
print(conf_matrix_svm)
print("SVM Accuracy Training : ", accuracy_svm_train)
print("SVM Accuracy Testing  : ", accuracy_svm_test)

"""#### Heatmap Confusion Matrix"""

# Membuat heatmap dari confusion matrix
svm_heatmap = sns.heatmap(conf_matrix_svm, annot=True, cmap='Greens')

# Mengatur judul dan label
svm_heatmap.set_title('Confusion Matrix Model SVM\n\n')
svm_heatmap.set_xlabel('\nPredicted Values')
svm_heatmap.set_ylabel('Actual Values ')

# Mengatur label x dan y
svm_heatmap.xaxis.set_ticklabels(['False', 'True'])
svm_heatmap.yaxis.set_ticklabels(['False', 'True'])

"""#### Save Metric Evaluasi"""

# Simpan Model untuk Analisis
models.loc['train_acc','SVM'] = accuracy_svm_train
models.loc['test_acc','SVM'] = accuracy_svm_test

"""### Algoritma Decsion Tree

Algoritma Decision merupakan algoritma machine learning tipe supervised learning yang umumnya digunakan pada permasalahan klasifikasi atau regresi. Dari namanya bisa diketahui bahwa decision tree menggambarkan sebuah pohon dengan banyak cabang. Melalui penggambaran tersebut algoritma ini bekerja dengan membagi data berdasarkan fitur-fitur yang ada, membangun struktur pohon keputusan yang berupa cabang-cabang (decisions) dan daun (outcomes).

Kelebihan :

- Decision tree sangat mudah dipahami dan diinterpretasikan.
- Decision tree dapat menangani berbagai jenis data tanpa perlu normalisasi.
- Decision tree relatif cepat dalam pelatihan dan dapat digunakan untuk dataset besar.

Kekurangan :

-  Decision tree cenderung overfit pada data jika pohon terlalu dalam, mempelajari noise dari data.
- Algoritma ini bisa sangat sensitif terhadap fluktuasi kecil dalam data, yang bisa menghasilkan pohon yang sangat berbeda.
- Decision tree mungkin tidak bekerja baik untuk data yang memiliki hubungan yang sangat non-linear dan kompleks.

#### Create Model
"""

# Model Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)

"""#### Predict"""

# Prediksi dengan Model Decision Tree
y_pred_dt = dt.predict(X_test)

"""#### Metric Evaluasi"""

# Menghitung Confusion Matrix dan Accuracy
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)
accuracy_dt_train = accuracy_score(y_train, dt.predict(X_train))
accuracy_dt_test = accuracy_score(y_test, y_pred_dt)

print("Decision Tree Confusion Matrix  : ")
print(conf_matrix_dt)
print("Decision Tree Accuracy Training : ", accuracy_dt_train)
print("Decision Tree Accuracy Testing  : ", accuracy_dt_test)

"""#### Heatmap Confusion Matrix"""

# Membuat heatmap dari confusion matrix
dt_heatmap = sns.heatmap(conf_matrix_dt, annot=True, cmap='Greens')

# Mengatur judul dan label
dt_heatmap.set_title('Confusion Matrix Model Decision Tree\n\n')
dt_heatmap.set_xlabel('\nPredicted Values')
dt_heatmap.set_ylabel('Actual Values ')

# Mengatur label x dan y
dt_heatmap.xaxis.set_ticklabels(['False', 'True'])
dt_heatmap.yaxis.set_ticklabels(['False', 'True'])

"""#### Save Metric Evaluasi"""

# Simpan Model untuk Analisis
models.loc['train_acc','Decision Tree'] = accuracy_dt_train
models.loc['test_acc','Decision Tree'] = accuracy_dt_test

"""### Algoritma Random Forest

Algoritma Random Forest merupakan algoritma machine learning tipe supervised learning yang umumnya digunakan pada permasalahan klasifikasi atau regresi. Merupakan algoritma lanjutan decision tree dengan banyaknya pohon seperti layaknya hutan bisa dikatakan ensemble method decision tree untuk membuat keputusan. Setiap pohon dalam hutan (forest) dilatih dengan subset acak dari data dan fitur, kemudian hasilnya digabungkan untuk membuat prediksi akhir (dengan voting untuk klasifikasi atau rata-rata untuk regresi).

Kelebihan :

- Karena menggunakan banyak pohon keputusan, Random Forest dapat mengurangi overfitting yang sering terjadi pada decision tree tunggal.
- Random Forest sering memberikan hasil yang sangat akurat dibandingkan dengan model tunggal seperti decision tree.
- Random Forest dapat menangani data yang besar dan memiliki banyak fitur dengan baik.

Kekurangan :

-  Meskipun lebih akurat, model Random Forest sulit untuk dipahami dan dijelaskan dibandingkan dengan decision tree tunggal.
- Pelatihan Random Forest memerlukan waktu yang lebih lama dibandingkan dengan algoritma tunggal seperti decision tree karena banyaknya pohon yang dilibatkan.
- Random Forest membutuhkan lebih banyak memori untuk menyimpan banyak pohon.

#### Create Model
"""

# Model Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

"""#### Predict"""

# Prediksi dengan Model Random Forest
y_pred_rf = rf.predict(X_test)

"""#### Metric Evaluasi"""

# Menghitung Confusion Matrix dan Accuracy
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
accuracy_rf_train = accuracy_score(y_train, rf.predict(X_train))
accuracy_rf_test = accuracy_score(y_test, y_pred_rf)

print("Random Forest Confusion Matrix  : ")
print(conf_matrix_rf)
print("Random Forest Accuracy Training : ", accuracy_rf_train)
print("Random Forest Accuracy Testing  : ", accuracy_rf_test)

"""#### Heatmap Confusion Matrix"""

# Membuat heatmap dari confusion matrix
rf_heatmap = sns.heatmap(conf_matrix_rf, annot=True, cmap='Greens')

# Mengatur judul dan label
rf_heatmap.set_title('Confusion Matrix Model Random Forest\n\n')
rf_heatmap.set_xlabel('\nPredicted Values')
rf_heatmap.set_ylabel('Actual Values ')

# Mengatur label x dan y
rf_heatmap.xaxis.set_ticklabels(['False', 'True'])
rf_heatmap.yaxis.set_ticklabels(['False', 'True'])

"""#### Save Metric Evaluasi"""

# Simpan Model untuk Analisis
models.loc['train_acc','Random Forest'] = accuracy_rf_train
models.loc['test_acc','Random Forest'] = accuracy_rf_test

"""### Algoritma Boosting (XGBoost)

Algoritma Boosting memiliki banyak jenisnya diantaranya AdaBoost, Gradient Boosting dan XGBoost. Boosting adalah ensemble method yang berfokus pada meningkatkan akurasi model dengan menggabungkan beberapa model yang lebih lemah (weak learners) menjadi model yang lebih kuat. Setiap model berikutnya dilatih untuk mengoreksi kesalahan dari model sebelumnya, sehingga dapat meningkatkan prediksi secara bertahap. Pada projek ini menggunakan XGBoost sebagai Boosting Algorithm.

Kelebihan :

- Boosting sering memberikan hasil yang sangat akurat, bahkan pada data yang kompleks, dengan meningkatkan performa model secara bertahap.
- Boosting dapat menangani data yang tidak seimbang (misalnya kelas yang jarang muncul) dengan lebih baik.
- Boosting dapat mengubah model yang lemah menjadi model yang sangat kuat.

Kekurangan :

-  Karena melibatkan beberapa model, pelatihan algoritma boosting bisa memakan waktu lebih lama dibandingkan dengan model lain.
- Meskipun algoritma boosting dapat menangani overfitting lebih baik, jika tidak hati-hati, boosting bisa terlalu berfokus pada data latih dan mengarah pada overfitting.
- Model boosting, seperti Random Forest, cenderung sulit untuk dipahami dan dijelaskan karena melibatkan banyak model.

#### Create Model
"""

# Update Nama Kolom X_train
X_train_XGBoost = X_train.rename(columns={
    'Air temperature [K]': 'Air_temperature_K',
    'Process temperature [K]': 'Process_temperature_K',
    'Rotational speed [rpm]': 'Rotational_speed_rpm',
    'Torque [Nm]': 'Torque_Nm',
    'Tool wear [min]': 'Tool_wear_min',
    'Type_H': 'Type_H',
    'Type_L': 'Type_L',
    'Type_M': 'Type_M',
    'Failure Type_Heat Dissipation Failure': 'Failure_Type_Heat_Dissipation_Failure',
    'Failure Type_No Failure': 'Failure_Type_No_Failure',
    'Failure Type_Overstrain Failure': 'Failure_Type_Overstrain_Failure',
    'Failure Type_Power Failure': 'Failure_Type_Power_Failure',
    'Failure Type_Random Failures': 'Failure_Type_Random_Failures',
    'Failure Type_Tool Wear Failure': 'Failure_Type_Tool_Wear_Failure'
}, inplace=True)
X_train_XGBoost = X_train
X_train_XGBoost.head()

# Update Nama Kolom X_test
X_test_XGBoost = X_test.rename(columns={
    'Air temperature [K]': 'Air_temperature_K',
    'Process temperature [K]': 'Process_temperature_K',
    'Rotational speed [rpm]': 'Rotational_speed_rpm',
    'Torque [Nm]': 'Torque_Nm',
    'Tool wear [min]': 'Tool_wear_min',
    'Type_H': 'Type_H',
    'Type_L': 'Type_L',
    'Type_M': 'Type_M',
    'Failure Type_Heat Dissipation Failure': 'Failure_Type_Heat_Dissipation_Failure',
    'Failure Type_No Failure': 'Failure_Type_No_Failure',
    'Failure Type_Overstrain Failure': 'Failure_Type_Overstrain_Failure',
    'Failure Type_Power Failure': 'Failure_Type_Power_Failure',
    'Failure Type_Random Failures': 'Failure_Type_Random_Failures',
    'Failure Type_Tool Wear Failure': 'Failure_Type_Tool_Wear_Failure'
}, inplace=True)
X_test_XGBoost = X_test
X_test_XGBoost.head()

# Model XGBoost
xgb = XGBClassifier(random_state=42)
xgb.fit(X_train_XGBoost, y_train)

"""#### Predict"""

# Prediksi dengan Model XGBoost
y_pred_xgb = xgb.predict(X_test_XGBoost)

"""#### Metric Evaluasi"""

# Menghitung Confusion Matrix dan Accuracy
conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)
accuracy_xgb_train = accuracy_score(y_train, xgb.predict(X_train))
accuracy_xgb_test = accuracy_score(y_test, y_pred_xgb)

print("XGBoost Confusion Matrix  : ")
print(conf_matrix_xgb)
print("XGBoost Accuracy Training : ", accuracy_xgb_train)
print("XGBoost Accuracy Testing  : ", accuracy_xgb_test)

"""#### Heatmap Confusion Matrix"""

# Membuat heatmap dari confusion matrix
xgb_heatmap = sns.heatmap(conf_matrix_xgb, annot=True, cmap='Greens')

# Mengatur judul dan label
xgb_heatmap.set_title('Confusion Matrix Model XGBoost\n\n')
xgb_heatmap.set_xlabel('\nPredicted Values')
xgb_heatmap.set_ylabel('Actual Values ')

# Mengatur label x dan y
xgb_heatmap.xaxis.set_ticklabels(['False', 'True'])
xgb_heatmap.yaxis.set_ticklabels(['False', 'True'])

"""#### Save Metric Evaluasi"""

# Simpan Model untuk Analisis
models.loc['train_acc','XGBoost'] = accuracy_xgb_train
models.loc['test_acc','XGBoost'] = accuracy_xgb_test

"""### Perbandingan 5 Model

Dari kelima model yang sudah dibuat dari akurasinya saja yang memiliki nilai tertinggi ada pada model algoritma decision tree, random forest dan algoritma XGBoost. Keduanya menghasilkan nilai yang mirip termasuk confusion matriknya. Namun berdasarkan kelebihan dan kekurangannya bisa dibilang XGBoost jauh lebih baik karena memiliki keunggulan dalam menangani data yang tidak seimbang (misalnya kelas yang jarang muncul) dengan lebih baik dan kebutuhan memory yang lebih sedikit dibandingkan dengan Random Forest. Random Forest dibentuk dari esemble method Decision Tree dengan banyak pohon sehingga kurang cocok apabila dataset akan berkembang lebih besar. XGBoost bisa dikatakan sebagai solusi atas dataset besar kedepannya apabila dikembangkan.
"""

models

"""## Model Evaluasi

Selain menggunakan metrik akurasi dan confusion matrix pada bagian ini dilihat juga metrik evaluasi ROC Curve dan AUC untuk menentukan mana yang lebih baik secara mendalam. Berikut beberapa penjelasan metrik evaluasi yang digunakan.
- Akurasi : merupakan pengukuran proporsi prediksi yang benar terhadap total data. Cocok untuk kasus klasifikasi jika data tidak memiliki ketidakseimbangan kelas (class imbalance).
- Confusion Matrix : Menggunakan True Positives (TP), True Negatives (TN), False Positives (FP), dan False Negatives (FN) untuk memberikan gambaran yang lebih mendalam mengenai kinerja model.
- ROC Curve & AUC :
  - ROC Curve menggambarkan trade-off antara True Positive Rate (Recall) dan False Positive Rate (FPR) pada berbagai threshold.
  - AUC adalah ukuran kinerja keseluruhan dari model klasifikasi, semakin tinggi AUC, semakin baik model dalam membedakan antara kelas positif dan negatif.

#### Model Evaluasi Akurasi
"""

# Model Evaluasi Akurasi
print('Hasil Evaluasi Metrik Akurasi \n')
print(models)

"""#### Model Evaluasi ROC AUC"""

# Buat variabel untuk menyimpan AUC dari setiap model
roc_auc = pd.DataFrame(index=['train', 'test'], columns=['KNN','SVM','Decision Tree','Random Forest','XGBoost'])

# Dictionary untuk setiap model
model_dict = {
    'KNN': knn,
    'SVM': SVC(probability=True, random_state=42), # SVC perlu probability=True untuk menghitung probabilitas
    'Decision Tree': dt,
    'Random Forest': rf,
    'XGBoost': xgb
}

# Fungsi untuk menghitung ROC AUC
for name, model in model_dict.items():
    model.fit(X_train, y_train)

    # Prediksi probabilitas untuk ROC (menggunakan predict_proba untuk probabilitas)
    y_train_prob = model.predict_proba(X_train)[:, 1]  # Ambil probabilitas untuk kelas positif
    y_test_prob = model.predict_proba(X_test)[:, 1]    # Ambil probabilitas untuk kelas positif

    # Hitung ROC Curve dan AUC
    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob)
    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)

    # Simpan AUC ke dalam DataFrame
    roc_auc.loc['train', name] = auc(fpr_train, tpr_train)
    roc_auc.loc['test', name] = auc(fpr_test, tpr_test)

# Tampilkan Hasil ROC AUC
print('Hasil Evaluasi Metric ROC AUC \n')
print(roc_auc)

"""Dari hasil evaluasi ROC AUC diatas bisa dilihat jika model XGBoost memiliki nilai yang tinggi sehingga hasilnya bisa dijadikan acuan mendalam dari model akurasi.

#### Evaluasi

Melalui hasil yang sudah dibuat dari mulai pembuatan model hingga membantuk metrik evaluasi menjadi jawaban atas problem statement yang ditanyakan di awal.
- Sistem seperti apa yang dibuat dalam upaya menentukan prediksi perawatan mesin yang baik?

  Goals : Sistem prediksi perawatan mesin dibuat melalui sistem klasifikasi dengan integrasi kecerdasan buatan berbasis machine learning sistem.

  Answer : Pada model machine learning yang sudah dibuat bisa dilihat bahwa model sangat beradaptasi dengan data-data mesin sehingga mampu memberikan akurasi yang besar. Hanya dengan data kurang lebih 10000 akurasi bisa mencapai leboh dari 90% untuk semua model baik training beserta maupun tahap pengujian dengan sampel 20%. Sehingga sistem prediksi pemeliharaan mesin sangat cocok dalam upaya menentukan prediksi mesin mana yang perlu mendapatkan pemeliharaan segera maupun tidak.

- Faktor apa yag paling berpengaruh dalam menentukan prediksi perawatan mesin?

  Goals : Faktor yang paling berpengaruh terhadap prediksi perawatan mesin dapat ditentukan melalui korelasi antar faktor terhadap kelas kategori kualitas mesin.

  Answer : Melalui heatmap pada bagian EDA - Multivariate Anlysis Numerical Features terdapat gambaran korelasi target terhadap semua variabel numeric lainnya. Heatmap yang memiliki nilai kearah positif mempunyai korelasi yang kuat sebaliknya nilai negatif mempunyai korelasi yang lemah. Sehingga melalui heatmap tersebut bisa disimpulkan bahwa korelasi yang kuat terhadap fitur Target yaitu Torque (0.22), Tool wear (0.12), Air temperature (0.09) dan Process temperature (0.04). Rotational speed (-0.17) menandakan bahwa variabel ini memiliki korelasi lemah dengan target sedangkan untuk UID tidak memiliki korelasi apapun karena merupakan nilai unik per record mesin.

- Mesin seperti apa yang mempunyai kualitas baik dan kualitas buruk sehingga perlu dilakukan perawatan?

  Goals : Mesin dengan kualitas baik dan buruk bisa dilihat dari faktor-faktor yang sudah tersedia.

  Answer : Jawabannya akan berkaitan dengan jawaban dari pertanyaan kedua, melalui hasil heatmap. Mesin dengan kualitas baik pasti memiliki nilai Target 0 sedangkan kualitas buruk perlu dilakukan pemeliharaan memiliki nilai Target 1. Korelasi dari heatmap menghubungkan antara variabel numerik dengan fitur Target yang mana kualitas baik diidentifikasi berdasarkan variabel Torque, Tool wear, Air temperature dan Process temperature. Melalui persebaran datanya Target dengan nilai 1 memenuhi 9263 data hampir 97% dari dataset memiliki nilai mesin kualitas baik atau No Failure. Mesin dengan kualitas baik melalui hasil describe memiliki nilai rata-rata Torque 39.98Nm, Tool wear 107.95min, Air temperature 300K dan Process temperature 310K. Mesin dengan kualitas buruk memiliki nilai yang tinggi melebihi rata-rata atau dengan nilai maksimum Torque 76Nm, Tool wear 253min, Air temperature 304K dan Process temperature 313K.

Solution Statement

- Membuat sistem prediksi yang berbasis machine learning dengan 5 pilihan algoritma diantaranya KNN, SVM, Decision Tree, Random Forest dan XGBoost. Diambil salah satu algoritma dengan akurasi terbaik dalam melakukan prediksi data test.

  Dampak : Dengan membuat 5 model machine learning dalam membuat model prediksi bisa diketahui manakah model yang cukup baik diterapkan dalam sistem prediksi. Karena masing-masing algoritma mempunyak keunggulan dan kekurangan. Dilihat dari akurasi training dan testing bisa cukup yakin menggunakan akurasi yang besar. Dari akurasi tersebut bisa memprediksi dengan tepat pada tahap pengujian sehingga bisa diterapkan pada sistem prediksi.

- Metrik evaluasi pada model klasifikasi umumnya digunakan accuracy, precision, recall, F-1 score dan confusion matrix. Metrik evaluasi yang disebutkan mengukur ketepatan dalam mengklasifikasikan suatu ketagori bergantung pada jenis data, imbangan kelas dan tujuan spesifik model.

  Dampak : Metrik evaluasi ini sebagai acuan daripada penentuan model algorima terbaik. Dengan 5 algoritma diatas untuk dapat menguku mana yang lebih baik dibutuhkan metrik evaluasi. Metrik evaluasi diatas masih terdapat bebebrapa kesamaa hasil pada algoritma decision tree, random forest dan XGBoost. Sehingga pada projek ini ada tambahan metrik untuk mengukur ROC AUC dan hasilnya bisa mengeliminasi mana model yang terbaik yaitu XGBoost. Efek dari pemilihan metrik ini cukup besar dalam penentuan model algoritma terbaik.

## Kesimpulan

Mesin memiliki batasan dalam penggunaannya yang bisa disebabkan oleh banyak faktor internal maupun eksternal. Sehingga perlu dilakukan pemeliharaan mesin agar bisa terawat dan bisa digunakan dalam waktu panjang. Pemeliharaan bisa bersifat kontinyu namun juga bisa dilakukan secara spontan apabila memenuhi ciri-ciri mesin dengan kualitas buruk. Kualitas mesin yang buruk memiliki ciri yang bisa di analisis dan di prediksi menggunakan model machine learning. Projek yang sudah dibuat menggunakan 5 model machine learning yaitu KNN, SVM, Decision Tree, Random Forest dan XGBoots. Kelima model menghasilkan nilai akurasi diatas 90% tetapi model dengan akurasi terbaik ada 3 yaitu Decision Tree, Random Forest dan XGBoost dengan memenuhi akurasi train sebesar 100% dan akurasi test sebesar 99.87%. Melalui metrik evaluasi ROC AUC bisa terlihat lebih mendalam akurasi terbaik dari ketiga model menghasilkan model dengan akurasi terbaik yaitu XGBoost ROC AUC train sebesar 100% dan ROC AUC test sebesar 97,56%. XGBoost sebagai pilihan model machine learning yang tepat selain akurasi dan ROC AUC yang tinggi terdapat beberapa kelebihan yaitu mampu menangani data yang tidak seimbang (misalnya kelas yang jarang muncul) dengan lebih baik dan kebutuhan memory yang lebih sedikit dibandingkan dengan keempat algoritma lainnya.

## Referensi
[1] K. Purnachand. etc, "Predictive Maintenance of Machines and Industrial Equipment", IEEE, 2021.

[2] Matzka Stephan, "Explainable  Artificial Intelligence for Predictive Maintenance Applications", IEEE, 2020.

[3] Petr Stodola and Jiˇrí Stodola, "Model of Predictive Maintenance of Machines and Equipment", IEEE, 2019.
"""

!pip freeze requirements.txt